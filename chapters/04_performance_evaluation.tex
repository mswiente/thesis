%!TEX root = ../thesis.tex
%******************************************************************************
\chapter{Performance Evaluation of Batch and Message-based Systems}\label{ch:performance_evaluation}
%******************************************************************************

\section{Introduction}\label{sec:ch4_introduction}

Traditionally, business information systems for bulk data processing are implemented as batch processing systems. Batch processing delivers high throughput but cannot provide near-time processing of data, that is the end-to-end latency of such a system is high. 

A lower end-to-end latency can be achieved by using message-based processing, for example by utilising a message-oriented middleware for the integration of the services that form the business information system. While this approach is able to deliver near-time processing, it is hardly capable for bulk data processing due to the additional communication over- head for each processed message. Therefore, message-based processing is ususally not considered for building a system for bulk data processing requiring high throughput.

This chapter compares the performance of a batch and message-based system. The main objectives of this comparison are:

\begin{itemize}
  \item What is the impact of different processing styles, that is batch and message-based processing, on throughput and latency?
  \item What is the impact of data granularity on latency and throughput when using a message-based processing style?  
\end{itemize}

To find solutions for these questions, the following approach has been taken:

\begin{itemize}
	\item Two prototypes of a billing system for each processing type (see Section \ref{sec:ch4_prototype}) have been built. 
	\item A performance evaluation has been conducted to compare the prototypes with each other with the focus on throughput and latency (see Section \ref{sec:ch4_evaluation}).
	\item To evaluate the impact of different aggregatation sizes on throughput and latency, the messaging prototype has been extended with an aggregator. A performance test has been conducted with different static aggregation sizes (see Section \ref{sec:ch4_impact_granularity}).
\end{itemize}

This chapter is organised as follows. Section \ref{sec:ch4_prototype} introduces the batch and message-based prototype systems that have been implemented. To compare the performance characterics of the two processing types, batch processing and message-based processing, a performance evaluation has been conducted, which is presented in Section \ref{sec:ch4_evaluation}. Section \ref{sec:ch4_impact_granularity} shows the impact of data granularity on throughput and latency of the messaging prototype. Section \ref{sec:ch4_related_work} gives an overview of other work related to the contents of this chapter. Finally, this chapter concludes with a summary in Section \ref{sec:ch4_summary} 

\section{A real world example  application}\label{sec:ch4_prototype}
This section introduces the two prototypes of a billing system that have been built to evaluate the performance of batch and message-based processing.

A billing system is a distributed system consisting of several sub components that process the different billing sub processes like mediation, rating, billing and presentment (see Figure \ref{fig:ch4_billing_process}).



\begin{figure}[htbp]
	\centering
	\includegraphics[width=\columnwidth]{billing_process}
	\caption{Billing process}
	\label{fig:ch4_billing_process}
\end{figure}

The mediation components receive usage events from delivery systems, like switches and transform them into a format the billing system is able to process. For example, transforming the event records to the internal record format of the rating and billing engine or adding internal keys that are later needed in the process. The rating engine assigns the events to the specific customer account, called guiding, and determines the price of the event, depending on the applicable tariff. It also splits events if more than one tariff is applicable or the customer qualifies for a discount. The billing engine calculates the total amount of the bill by adding the rated events, recurring and one-time charges and discounts. The output is processed by the presentment components, which format the bill, print it, or present it to the customer in self-service systems, for example on a website.

In order to compare batch and message-based types of processing, two different prototypes of a billing application have been developed. Each prototype implements the mediation and rating steps of the billing process. Figure \ref{fig:ch4_prototype_components} shows the components of the billing prototype: 
\begin{itemize}
	\item \textbf{Event Generator}\\
	The \emph{Event Generator} generates the calling events, i.e. the \ac{CDR} that are processed by the billing application.
	\item \textbf{Mediation}\\
	The \emph{Mediation} component checks wether the calltime of the calldetail record exceeds the minimal billable length or if it belongs to a flatrate account and sets the corresponding flags of the record. The output of the \emph{Mediation} component are \ac{NCDR} that are further processed by the \emph{Rating} component.
	\item \textbf{Rating}\\
	The \emph{Rating} component processes the output from the \emph{Mediation} component. It assigns the calldetail record to a customer account and determines the price of the call event by looking up the correspondant product and tariff in the \emph{Master Data DB}. The output of the \emph{Rating} component (costed events) is afterwards written to the \emph{Costed Events DB}.
	\item \textbf{Master Data DB}\\
	The \emph{Master Data DB} contains products, tariffs and accounts used by the \emph{Event Generator} and the \emph{Rating} component.
	\item \textbf{Costed Events DB}\\
	The \emph{Costed Events DB} contains the result of the \emph{Rating} component, i.e. the costed events.
\end{itemize}

\begin{figure}[htbp]
	\centering
	\includegraphics[width=\columnwidth]{prototype_components}
	\caption{Components of the billing application prototype}
	\label{fig:ch4_prototype_components}
\end{figure}

The prototypes are implemented with Java 1.6 using \ac{JPA} for the data-access layer and a MySQL database. See Table \ref{table:ch4_frameworks} for complete list of technologies and frameworks used for the implementation of the prototypes.

\begin{table}
	%\renewcommand{\arraystretch}{1.3}
	\centering
	\begin{tabularx}{\textwidth}{@{} l X @{}}
		\caption{Technologies and frameworks used for the implementation of the prototypes} \label{table:ch4_frameworks}\\
		\toprule
		\bfseries Language & Java 1.6\\
		\midrule
		\bfseries Dependancy Injection & Spring\\
		\midrule
		\bfseries Persistence API & OpenJPA (JPA 2.0)\\
		\midrule
		\bfseries Database & MySQL\\
		\midrule
		\bfseries Logging & Logback\\
		\midrule
		\bfseries Test & JUnit\\
		\midrule
		\bfseries Batch Framework & Spring Batch\\
		\midrule
		\bfseries Messaging Middleware & Apache Camel\\
		\midrule
		\bfseries Other Frameworks & Joda-Time, Apache Commons\\
		\bottomrule
	\end{tabularx}
\end{table}

\subsection{Common Architecture} % (fold)
\label{sub:ch4_common_architecture}

The objective of this performance evaluation is to compare the different processing styles, batch and single-event processing, with each other.
It needs to be ensured that the comparison only includes the different processing styles. Therefore, the prototypes should only differ in their processing style, all other aspects should be the same, for example the business functionality, data access and datamodel.

To ensure the comparability between the prototypes, a common architecture used by both prototypes has been designed and implemented.

It consists of the following components (see Figure \ref{fig:ch4_technical_integration}):

\begin{itemize}
	\item \textbf{Integration Layer}\\
	Implements the integration style, i.e. file-based integration and message-based integration.
	\item \textbf{Business Service}\\
	Implements the business functionality, i.e. mediation and rating.
	\item \textbf{Data Access Layer}\\Implements the data access.
\end{itemize}

\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.7\textwidth]{technical_integration}
	\caption{The prototypes share the same business components, database and data-access layer.}
	\label{fig:ch4_technical_integration}
\end{figure}

% subsection common_architecture (end)

\subsubsection{Business Services}

The business functionality, mediation and rating, is implemented by business services, which are used by both prototypes (see Figure \ref{fig:ch4_business_services}):

\begin{itemize}
	\item \textbf{MediationProcessor}\\
	Implements the mediation functionality.
	\item \textbf{RatingProcessor}\\
	Implements the rating functionality.
\end{itemize}

\begin{figure}[htbp]
	\centering
	\includegraphics[width=\textwidth]{ch4_business_services}
	\caption{Business services}
	\label{fig:ch4_business_services}
\end{figure}

\subsubsection{Integration Layer}

The integration layer implements the different integration styles of the two prototypes. The batch prototype uses a batch layer which provides components for file-based data integration, transaction and control of batch processes.

The messaging prototype uses a messaging middleware for exchanging messages (see Figure \ref{fig:ch4_messaging_integration}). The messaging middleware provides components for the transport, transformation and routing of messages.

\begin{figure}[htbp]
	\centering
	\subfloat[Batch integration]{\includegraphics[width=0.4\textwidth]{ch4_batch_integration}\label{fig:ch4_batch_integration}}
	\qquad
	\subfloat[Message-based integration]{\includegraphics[width=0.4\textwidth]{ch4_messaging_integration}\label{fig:ch4_messaging_integration}}
	\caption{The prototypes use different integration layers.}
\end{figure}

\subsubsection{Data model}
The prototypes use a common data model as shown in Figure \ref{fig:ch4_data_model}. It consists of the following entities:

\begin{itemize}
	\item \textbf{Customer}\\
	Represents a customer. A customer has an account and one or many products.
	\item \textbf{Account}\\
	Contains payment informations of a customer.
	\item \textbf{Product}\\
	A product such as a voice or data plan.
	\item \textbf{Tariff}\\
	The tariff of a product. Defines the price of a product.
	\item \textbf{EventSource}\\
	Mobile number or IP associated with a product instance of a customer.
	\item \textbf{CostedEvent}\\
	An event that has been rated by the rating component.
	\item \textbf{SkippedEvent}\\
	An event that has been skipped by the mediation component. For example a flat rate event.
	\item \textbf{CustomerProduct}\\
	Contains the booked products of a customer. A customer can have zero or many products.
	\item \textbf{CustomerProductTariff}\\
	Contains the tariffs of a product. A product can have one or many tariffs.
\end{itemize}

\begin{figure}[htbp]
	\centering
	\includegraphics[width=\columnwidth]{ch4_logical_datamodel}
	\caption{Logical data model of the prototype}
	\label{fig:ch4_data_model}
\end{figure}

\subsubsection{Data Access Layer}

The data access layer provides common access to the database by using the \ac{ORM} framework OpenJPA. All business domain entities have been generated from the data model using the toolchain provided by OpenJPA. The data access for retrieving, creating and update of the domain entities is implemented using the DAO pattern \citep{Alur:2003:CJP:863711}.

\subsection{Batch prototype}
The batch prototype implements the billing application utilizing the batch processing type. It uses the Spring Batch framework \citep{springbatch}, a Java framework that facilitates the implementation of batch applications by providing basic building blocks for reading, writing and processing data.

Figure \ref{fig:ch4_batch_prototype} shows the architecture of the batch prototype. It consists of two nodes, mediation batch and rating batch, each implemented as a separate spring batch application. The nodes are integrated using Apache Camel \citep{apachecamel}, an Java integration framework based on enterprise integration patterns, as described by \cite{Hohpe:2003fk}. Apache Camel is responsible for listening on the file system, calling the Spring batch application when a file arrives and transferring the output from the mediation batch node to the rating batch node using \ac{FTP}.

\begin{figure}[htbp]
	\centering
	\includegraphics[width=\columnwidth]{batch_prototype}
	\caption{Batch prototype}
	\label{fig:ch4_batch_prototype}
\end{figure}

The batch prototype performs the following steps:
\begin{enumerate}
	\item The \emph{Event generator} generates call detail records and writes them to a single file.
	\item The \emph{Mediation component} opens the file, processes it and writes the output to a single output file. The output file is getting transfered using \ac{FTP} to the \emph{Rating component}.
	\item The \emph{Rating component} opens the file, processes it and writes the costed events to the costed event database.
\end{enumerate}

\subsubsection{Implementation details}
The main entities in Spring Batch are Jobs and Steps. A Job defines the processing flow of the batch application and consists of one or more steps. A basic step is comprised of an item reader, item processor and item writer (see Figure \ref{fig:ch4_spring_batch_step}). 
\begin{figure}[htbp]
	\centering
	\includegraphics[width=\columnwidth]{spring_batch_step}
	\caption{A Step consists of an item reader, item processor and item writer}
	\label{fig:ch4_spring_batch_step}
\end{figure}

The item reader reads records of data in chunks, for example from a file, and converts them to objects. These objects are then processed by the item processor, which contains the business logic of the batch application. Finally, the processed objects are getting written to the output destination, for example a database, by the item writer.

\lstinputlisting[caption={Mediation batch job definition},label=listing:ch4_mediation_job]{listings/mediation_job.xml}

Listing \ref{listing:ch4_mediation_job} shows the definition of the mediation batch job \emph{mediationMultiThreadedJob}. It consists of two steps, the \emph{mediationMultiThreadedStep} (line 2) and the \emph{renameFileMultiThreadedStep} (line 10). The step \emph{mediationMultiThreadedStep} is multithreaded and uses 10 threads for processing. It consists of a \emph{rawUsageMultiThreadedEventReader} (line 6), a thread safe reader implementation that reads call detail records from the input file and converts them to objects, a \emph{rawUsageEventProcessor}, that processes the call detail objects by calling the mediation business logic and a \emph{loggingSimpleCdrWriter} (line 7), which writes the processed call detail objects to the output file. The step uses an commit interval of 1000, meaning that the input data is processed in chunks of 1000 records. After the input file has been processed by the \emph{mediationMultiThreadedStep} it is getting renamed to its final name by the \emph{renameFileMultiThreadedStep} (line 10).

The mediation batch job is integrated using Apache Camel. Listing \ref{listing:ch4_mediation_route} shows the definition of the mediation batch route.

\begin{lstlisting}[caption={Mediation batch route definition},label=listing:ch4_mediation_route]
public void configure() {
	from("file:data/input")
	.to("spring-batch:mediationMultiThreadedJob?jobLauncherRef=jobLauncher");
        
	from("file:data/output)
	.to("ftp://billing@localhost/src/data?password=billing");
}
\end{lstlisting}

It consists of two routes, the first route listens on the file system for incoming files (line 2) and calls the mediation batch job, when a file arrives (line 3). The second route transfers the output file of the mediation batch job to the rating batch node using \ac{FTP} (line 5-6).

Listing \ref{listing:ch4_rating_job} shows the definition of the rating batch job \emph{ratingMultiThreadedJob}. It consists of a single step \emph{ratingMultiThreadedStep} (line 2), which is comprised of a \emph{simpleCdrMultiThreadedItemReader}, which reads the normalized call detail records written by the mediation batch node, a \emph{simpleCdrProcessor}, that processes the normalized call detail records by calling the rating business logic and a \emph{costedEventWriter}, which writes the processed costed events to the Costed Events database (line 4).

\lstinputlisting[caption={Rating batch job definition},label=listing:ch4_rating_job]{listings/rating_job.xml}

\subsection{Messaging prototype}
\label{sec:ch04_messaging_prototype}

The messaging prototype implements the billing prototype utilizing the message-oriented processing type. It uses Apache Camel \citep{apachecamel} as the messaging middleware.

Figure \ref{fig:ch4_messaging_prototype} shows the architecture of the messaging prototype. It consists of three nodes, the billing route, mediation service and rating service. The billing route implements the main flow of the application. It is responsible for reading messages from the billing queue, extracting the payload, calling the mediation and rating service and writing the processed messages to the database. The mediation service is a webservice representing the mediation component. It is a SOAP service implemented using Apache CXF and runs inside an Apache Tomcat container. The same applies to the rating service, representing the rating component.

\begin{figure}[htbp]
	\centering
	\includegraphics[width=\columnwidth]{messaging_prototype}
	\caption{Message-based prototype}
	\label{fig:ch4_messaging_prototype}
\end{figure}

Listing \ref{listing:ch4_billing_route} shows the definition of the billing route using the Apache Camel fluent \ac{API}.
The billing route performs the following steps:

\begin{enumerate}
	\item The message is read from the billing queue using \ac{JMS} (line 5). The queue ist hosted by an Apache ActiveMQ instance.
	\item The message is unmarshalled using \ac{JAXB} (line 6).
	\item The \emph{Mediation service} is called by the CXF Endpoint of the billing route (line 7)
	\item The response of the \emph{Mediation webservice}, the normalized call detail record, is unmarshalled (line 8). 
	\item The \emph{Rating service} is called by the CXF Endpoint of the billing route (line 9).
	\item The response of the \emph{Rating webservice}, that is the costed event, is unmarshalled (line 10).
	\item The costed event is written to the \emph{Costed Events} DB (line 11).
\end{enumerate}

If an error occurs during the processsing of an event, it is written to an error \ac{JMS} queue (line 3).

\begin{lstlisting}[caption={Billing route definition},label=listing:ch4_billing_route]
public void configure() {
		
	errorHandler(deadLetterChannel("activemq:queue:BILLING.ERRORS"));
	
	from("activemq:queue:BILLING.USAGE_EVENTS")
		.unmarshal("jaxbContext")
		.to("cxf:bean:mediationEndpoint?dataFormat=POJO&defaultOperationName=processEvent")
		.process(new ProcessEventPostProcessor())
		.to("cxf:bean:ratingEndpoint?dataFormat=POJO&defaultOperationName=processCallDetail")
		.process(new ProcessCallDetailPostProcessor())
		.process(costedEventProcessor);
}
\end{lstlisting}

\section{Performance evaluation}\label{sec:ch4_evaluation}
To compare the performance characterics of the two processing types, batch processing and message-based processing, a performance evaluation has been conducted with the main focus on latency and throughput.

This section describes the approach and the results of the performance evaluation.

\subsection{Measuring points}
A number of measuring points have been defined for each prototype by breaking down the processing in single steps and assigning a measuring point to each step. Figure \ref{fig:ch4_measuring_points_batch} and \ref{fig:ch4_measuring_points_messaging} show the measuring points of the batch prototype and the messaging prototype. 

\begin{figure}[htpb]
	\centering
	\includegraphics[width=\columnwidth]{measuring_points_batch}
	\caption{Measuring points of the batch prototye}
	\label{fig:ch4_measuring_points_batch}
\end{figure}

\begin{figure}[htpb]
	\centering
	\includegraphics[width=\columnwidth]{measuring_points_messaging}
	\caption{Measuring points of the messaging prototype}
	\label{fig:ch4_measuring_points_messaging}
\end{figure}

A detailed description of each point is shown in Table \ref{table:ch4_measuring_points_batch} and \ref{table:ch4_measuring_points_messaging}.

\begin{table}
	%\renewcommand{\arraystretch}{1.3}
	\centering
	\begin{tabularx}{\textwidth}{@{} l X @{}}
		\caption{Measuring points of the batch prototype} \label{table:ch4_measuring_points_batch}\\
		\toprule
		\bfseries Measuring point & \bfseries Description\\
		\midrule
		PROC\_START & Timestamp denoting the start of processing an event\\
		\midrule
		PROC\_END & Timestamp denoting the end of processing an event\\
		\midrule
		FILE\_READ & Elapsed time for reading events from file\\
		\midrule
		MEDIATION & Elapsed time used by the mediation component\\
		\midrule
		FILE\_WRITE & Elapsed time for writing events to file\\
		\midrule
		FTP & Elapsed time for file transfer using FTP\\
		\midrule
		RATING & Elapsed time used by the rating component\\
		\midrule
		DB & Elapsed time for writing event to the database\\
		\bottomrule 
	\end{tabularx}
\end{table}

\begin{table}[htpb]
	\centering
	\begin{tabularx}{\textwidth}{@{} l X @{}}
		\caption{Measuring points of the messaging prototype} \label{table:ch4_measuring_points_messaging}\\
		\toprule
		\bfseries Measuring point & \bfseries Description\\
		\midrule
		PROC\_START & Timestamp denoting the start of processing an event\\
		\midrule
		PROC\_END & Timestamp denoting the end of processing an event\\
		\midrule
		JMS\_CONSUMER & Elapsed time processing a single event\\
		\midrule
		UNMARSHALL & Elapsed time for unmarshalling an event\\
		\midrule
		MEDIATION\_PROC & Elapsed time needed for calling the mediation service\\
		\midrule
		MEDIATION & Elapsed time used by the mediation component\\
		\midrule
		RATING\_PROC & Elapsed time needed for calling the rating service\\
		\midrule
		RATING & Elapsed time used by the rating component\\
		\midrule
		DB & Elapsed time for writing event to the database\\
		\bottomrule 
	\end{tabularx}
\end{table}

\subsection{Instrumentation}
A logging statement for each measuring point has been added at the appropriate code location of the prototypes using different techniques.

\begin{enumerate}
	\item \textbf{Directly in the code}\\Whenever possible, the logging statements have been inserted directly in the code. This has been the case, when the code that should be measured, has been written exclusively for the protoype, for example the mediation and rating components.
	\item \textbf{Delegation}\\When the code to instrument has been part of a framework that is configurable using Spring, an instrumented delegate has been used.
	\item \textbf{AOP}\\Finally, when the code that should get instrumented was part of a framework that was not configurable using Spring, the logging statements have been added using aspects, which are woven into the resulting class files using AspectJ.
\end{enumerate}

\subsection{Test environment}
\label{sec:ch4_test_environment}

The two prototypes have been deployed to an Amazon EC2 environment to conduct the performance evaluation, with the characterics described in Table \ref{table:ch4_amazon_ec2}.

\subsubsection{Batch prototype}

The batch prototype comprises two EC2 nodes, the \emph{Mediation Node} and the \emph{Rating Node}, containing the \emph{Mediation Batch} and the \emph{Rating Batch}, respectively. The \emph{Costed Event Database} is hosted on the \emph{Rating Node} as well. Figure \ref{fig:ch4_batch_deployment_model} shows the deployment diagramm of the Batch prototype.

\begin{figure}[htbp]
	\centering
	\includegraphics[width=\columnwidth]{batch_deployment_model}
	\caption{Batch prototype deployment on EC2 instances}
	\label{fig:ch4_batch_deployment_model}
\end{figure}

\subsubsection{Messaging Prototype}

The messaging prototype consists of three EC2 nodes, as shown in Figure \ref{fig:ch4_messaging_deployment_model}. The \emph{Master Node} hosts the \emph{ActiveMQ Server} which runs the JMS queue containining the billing events, the \emph{Billing Route}, which implements the processing flow of the prototype and the \emph{MySQL Database} containing the \emph{Costed Event Database}. The \emph{Mediation Node} and \emph{Rating Node} are containing the \emph{Mediation Service} and \emph{Rating Service}, respectively, with each service running inside an Apache Tomcat container.

\subsection{Clock Synchronization}

The clocks of the \emph{Mediation Node} and \emph{Rating Node} are synchronized with the clock of the \emph{Master Node} using PTPd \citep{ptpd}, an implementation of the \ac{PTP} \citep{IEEE_PTP}. The clock of the \emph{Master Node} itself is synchronised with a public timeserver using the \ac{NTP}. Using this approach, a sub-millisecond precision is achieved.

\begin{figure}[htbp]
	\centering
	\includegraphics[width=\columnwidth]{messaging_deployment_model}
	\caption{Messaging prototype deployment on EC2 instances}
	\label{fig:ch4_messaging_deployment_model}
\end{figure}

\begin{table}[htbp]
	\centering
	\begin{tabularx}{\textwidth}{@{} l X @{}}
		\caption{Amazon EC2 instance configuration} \label{table:ch4_amazon_ec2} \\
		\toprule
		\bfseries Instance type & M1 Extra Large (EBS optimized)\\
		\midrule
		\bfseries Memory & 15 GiB\\
		\midrule
		\bfseries Virtual Cores & 8 (4 cores x 2 units)\\
		\midrule
		\bfseries Architecture & 64-bit\\
		\midrule
		\bfseries EBS Volume & 10 GiB (100 IOPS)\\
		\midrule
		\bfseries Instance Store Volumes & 1690 GB (4x420 GB Raid 0)\\
		\midrule
		\bfseries Operating System & Ubuntu 12.04 LTS\\
		& (GNU/Linux 3.2.0-25-virtual x86\_64)\\
		\midrule 
		\bfseries Database & MySQL 5.5.24\\
		\midrule
		\bfseries Messaging Middleware & Apache ActiveMQ 5.6.0\\
		\bottomrule
	\end{tabularx}
\end{table}

\subsection{Preparation and execution of the performance tests}
For running the performance tests, the Master Data DB has been set up with a list of customers, accounts, products and tariffs with each prototype using the same database and data. While part of the testdata like the products and tariffs have been created manually, the relationship between the customers and the products have been generated by a test data generator.
\newpage
After setting up the master data, a number of test runs have been executed using different sizes of test data (1.000, 5.000, 10.000, 50.000, 100.000, 500.000, 1.000.000 records). To get reliable results, each test configuration has been run three times. Out of the three runs for each configuration, the run having the median processing time has been used for the evaluation.

For each test run, the following steps have been executed:
\begin{enumerate}
	\item \textbf{Generating test data}\\In case of the batch prototype, the event generator writes the test data to file. In case of the messaging prototype, the event generator writes the test data to a \ac{JMS} queue.
	\item \textbf{Running the test}\\Each prototype listens on the file system and the \ac{JMS} queue, respectively. Using the batch prototype, the processing starts when the input file is copied to the input folder of the mediation batch application by the event genarotor. Using the messaging prototype, the processing starts when the first event is written to the JMS queue by the test generator.
	\item \textbf{Validating the results}\\Processsing the log files written during the test run
	\item \textbf{Cleaning up}\\Deleting the created costed events from the DB.
\end{enumerate}

Before running the tests, each prototype has been warmed up by processing 10.000 records.

\subsection{Results} \label{sec:ch4_results}
The performance evaluation yields the following results.

\subsubsection{Throughput}

The throughput per second for a test run with $N$ records is defined as
\begin{displaymath}
{TP/s}_N = N / PT_N
\end{displaymath}
with $PT_N$ being the total processing time for $N$ records. 
Figure \ref{fig:ch4_result_throughput} shows the measured throughput of the batch and messaging prototypes. The messaging prototype is able to process about 70 events per second. The maximum throughput of the batch prototype is about 383 records per second which is reached with an input of 1.000.000 records.

\begin{figure}[htbp]
	\centering
	\includegraphics[width=\columnwidth]{throughput_result}
	\caption{Throughput}
	\label{fig:ch4_result_throughput}
\end{figure}

\subsubsection{Latency}\label{sec:result_latency}

Figure \ref{fig:ch4_result_latency} shows the measured latencies of the batch and messaging prototypes. To rule out peaks, the 95th percentile has been used, that is, 95\% of the measured latencies are below this value. In case of the batch prototype, the 95th percentile latency is a linear function of the amount of data. The latency increases proportionally to the number of processd records. In case of the messaging prototype, the 95th percentile latency is approximately a constant value which is independant of the number of processed records.

\begin{figure}[htbp]
	\centering
	\includegraphics[width=\columnwidth]{latency_result}
	\caption{Latency}
	\label{fig:ch4_result_latency}
\end{figure}

\subsubsection{Processing overhead}

The overhead of the batch prototype is about 7\% of the total processing time, independant of the number of processed records, as shown in Figure \ref{fig:ch4_overhead_batch}. This overhead contains file operations, such as opening, reading, writing and closing of input files, the file transfer between the Mediation and Rating Nodes and the database transactions to write the the processed event to the Costed Events DB.

\begin{figure}[htbp]
	\centering
	\includegraphics[width=\columnwidth]{overhead_batch}
	\caption{Overhead batch prototype}
	\label{fig:ch4_overhead_batch}
\end{figure}

On the contrary, the overhead of the messaging prototype is about 84\% of the total processing time (see Figure \ref{fig:ch4_overhead_messaging}). In case of the messaging prototype, the overhead contains the JMS overhead, that is the overhead for reading events from the message queue, the webservice overhead needed for calling the Mediation and Rating services including marshalling and unmarshalling of input data and the overhead caused the database transactions to write the processed events to the Costed Events DB. Most of the overhead is induced by the webservice overhead and the database overhead. Since every event is written to the database in its own transaction, the database overhead of the messaging prototype is much larger than the database overhead of the batch prototype.

\begin{figure}[htbp]
	\centering
	\includegraphics[width=\columnwidth]{overhead_messaging}
	\caption{Overhead messaging prototype}
	\label{fig:ch4_overhead_messaging}
\end{figure}

\subsubsection{System utilisation}

\begin{figure}[htbp]
	\centering
	\includegraphics[width=\columnwidth]{systemutilisation_batch}
	\caption{System utilisation batch prototype}
	\label{fig:ch4_systemutilisation_batch}
\end{figure}

The system utilisation has been measured using the sar (System Activity Report) command while running the performance tests. Figure \ref{fig:ch4_systemutilisation_batch} shows the mean percentage of CPU consumption at the user level (\%user) and the mean percentage of used memory (\%memused) for the Mediation node and Rating node of the Batch prototype.
The CPU utilisation of Medation Node and Ratig Node is about 2\% and 19\%, respectively. The memory utilisation increases slowly with the number of processed records.

Figure \ref{fig:ch4_systemutilisation_messaging} shows the mean CPU consumption and mean memory usage for the nodes of the Messaging prototype. The CPU utilisation of the Master Node, Mediation Node and Rating Node is about 9\%, 1\% and 6\%, respectively.
As the same with the batch prototye, the memory utilisation of the messaging prototype increases with the number of processed records. The memory utilisation of the master node peaks at about 38\% with 500000 processed records.
With 1000000 processed records, the memory utilisation is only about 25\%, which presumably can be accounted to the garbage collector.

\begin{figure}[htbp]
	\centering
	\includegraphics[width=\columnwidth]{systemutilisation_messaging}
	\caption{System utilisation messaging prototype}
	\label{fig:ch4_systemutilisation_messaging}
\end{figure}

\section{Impact of data granularity on throughput and latency}\label{sec:ch4_impact_granularity}
The results presented in Section \ref{sec:ch4_results} suggest that the throughput of the messaging prototype can be increased by increasing the granularity of the data that is beeing processed. Data granularity relates to the amount of data that is processed in a unit of work, for example in a single batch run or an event.
In order to examine this approach, we have repeated the performance tests using different package sizes for processing the data.

\begin{figure}[htbp]
	\centering
	\includegraphics[width=\columnwidth]{messaging_prototype_aggregator}
	\caption{The data granularity is controlled by an aggregator}
	\label{fig:ch4_messaging_prototype_aggregator}
\end{figure}

For this purpose, the messaging prototype has been extended to use an aggregator in the messaging route. The aggregator is a stateful filter which stores correlated messages until a set of messages is complete and sends this set to the next processing stage in the messaging route. In case of the messaging prototype, messages are not corelated to each other and also the messages can be processed in an arbitrary order. A set of messages is complete when it reaches the configured package size. In other scenarios, it is possible to corelate messages by specific data, for example an account number or by a business rule.

Listing \ref{listing:ch4_billing_route_aggregator} shows the definition of the billing route using the aggregator processor, which is provided by Apache Camel (line 7). The aggregator is configured using the correlation expression \lstinline$constant(true)$, which simply aggregates messages in order of their arrival and the aggregation strategy \lstinline$UsageEventsAggrationStrategy$, which implements the merging of incoming messages with already merged messages. The aggregation size is set by \lstinline$completionSize$. The specific value is set in a configuration file. As a fallback, \lstinline$completionTimeout$ defines a timeout in milliseconds to send the set of aggregated messages to the next processing stage before it has reached the defined aggregation size. \lstinline$parallelProcessing$ indicates that the aggregator should use multiple threads (default is 10) to process the finished sets of aggregated messages.

\begin{lstlisting}[caption={Billing route definition with an additional aggregator},label=listing:ch4_billing_route_aggregator]
public void configure() {
		
	errorHandler(deadLetterChannel("activemq:queue:BILLING.ERRORS"));
	
	from("activemq:queue:BILLING.USAGE_EVENTS")
		.unmarshal("jaxbContext")
		.aggregate(constant(true), new UsageEventsAggrationStrategy()).completionSize(completionSize).completionTimeout(completionTimeout).parallelProcessing()
		.to("cxf:bean:mediationEndpoint?dataFormat=POJO&headerFilterStrategy=#dropAllMessageHeadersStrategy&defaultOperationName=processEvents")
		.process(new ProcessEventsPostProcessor())
		.to("cxf:bean:ratingEndpoint?dataFormat=POJO&headerFilterStrategy=#dropAllMessageHeadersStrategy&defaultOperationName=processCallDetails")
		.process(new ProcessCallDetailsPostProcessor())
		.process(costedEventsProcessor);
}
\end{lstlisting}

Figure \ref{fig:ch4_throughput_aggregation} shows the impact of different aggregatation sizes on the throughput of the messaging prototype. For each test 100.000 events have been processed.
\begin{figure}[htbp]
	\centering
	\includegraphics[width=\columnwidth]{throughput_aggregation}
	\caption{Impact of different aggregation sizes on throughput}
	\label{fig:ch4_throughput_aggregation}
\end{figure}
The throughput increases constantly for $1<aggregation\_size<=50$ with a maximum of 673 events per second with $aggregation\_size=50$. Higher aggregation sizes than 50 do not further increase the throughput, it stays around 390 events per second. Surprisingly, the maximum throughput of 673 events per second even outperforms the throughput of the batch prototype which is about 383 records per second. This is presumably a result of the better multithreading capabilities of the camel framework.

Increasing the aggregation size also decreases the processing overhead, as shown in Figure \ref{fig:ch4_overhead_aggregation}. An aggregate size of 10 decreases the overhead by more than 50\% compared to an aggregate size of 1. Of course, the integration of the aggregator adds an additional overhead which is insignificant for $aggregation\_size>50$.
\begin{figure}[htbp]
	\centering
	\includegraphics[width=\columnwidth]{overhead_aggregation}
	\caption{Impact of different aggregation sizes on processing overhead}
	\label{fig:ch4_overhead_aggregation}
\end{figure}

The increased throughput achieved by increasing the aggregation size comes with the cost of a higher latency. Figure \ref{fig:ch4_latency_aggregation} shows the impact of different aggregation sizes on the 95th percentile latency of the messaging prototype. 
\begin{figure}[htbp]
	\centering
	\includegraphics[width=\columnwidth]{latency_aggregation}
	\caption{Impact of different aggregation sizes on latency}
	\label{fig:ch4_latency_aggregation}
\end{figure}

An aggregation size of 50, resulting in the maximum throughput of 673 events per seconds, shows a 95th percentile latency of about 68 seconds. This latency is significantly higher than the latency of the messaging system without message aggregation, which is about 0,15 seconds (see Section \ref{sec:result_latency}).

The results indicate that there is an optimal range for the aggregation size to control the throughput and latency of the system. Setting the aggregation size higher than a certain threshold leads to a throughput drop and latency gain. In case of our prototype, this threshold is between an aggregation size of 85 and 90. The observed throughput drop and latency gain is caused by a congestion in the aggregator. Messages are read faster from the queue than they are getting processed by the aggregator.

Figure \ref{fig:ch4_systemutilisation_aggregation} shows the impact of different aggregation sizes on the system utilisation. The CPU utilisation of the Master node shows a maximum of 30\% with an aggregation size of 25. An $aggregation\_size >= 90$ results in a CPU utilisation of about 15\%. The maximum memory utilisation of the Master node is 41\% with an aggregation size of 100.

The maximum system utilisation of the Rating node is 25\% with an aggregation size of 80. The memory utilisation is between 7-8\% irrespective of aggregation size. Maximum system and memory utilisation of the Mediation node are also irrespective of aggregation size, beeing less than 2\% and 8\%, respectively.

\begin{figure}[htbp]
	\centering
	\includegraphics[width=\columnwidth]{systemutilisation_aggregation}
	\caption{Impact of different aggregation sizes on system utilisation}
	\label{fig:ch4_systemutilisation_aggregation}
\end{figure}

When using high levels of data granularity, the messaging system is essentially a batch processing system, providing high throughput with high latency. To provide near-time processing an optimum level of data granularity would allow having the lowest possible latency with the lowest acceptable throughput.

\section{Discussion with respect to related work}\label{sec:ch4_related_work}
This section gives an overview of work related to the performance evaluation of batch and message-based systems presented in this chapter and discusses the approach that has been taken. 

Related work can be categorised in two different topics, performance measuring and performance prediction. 
Performance measuring is applied to evaluate if an implemented system meets its performance requirements and to spot possible performance problems.

While performance measuring can only be done when the relevant parts of a system are already implemented, performance prediction allows to predict the performance of a system in an early stage of development, before the system is available. It uses performance modelling to build a model of the system, which is then used for the performance evaluation. Common approaches for performance modelling use queueing networks, petri nets or simulations \citep{Balsamo:2004hn}.

\subsection{Performance Modelling}
Performance modeling allows to predict the performance of a system in an early stage of development. It facilitates for example capacity and resource planning before the system is already available or helps to evaluate design alternatives in regard of their performance impact.

\citet{Brebner:2008uq} developed a tool for performance modeling of Service-Oriented Architectures. It is comprised of SOA models, a simulation engine and a graphical user interface. The SOA models are generated from architectural artifacts such as UML sequence or deployment diagrams and automatically transformed into runtime models for execution.

An approach to predict the performance of J2EE applications using messaging services using queueing network models has been presented by \citet{Liu:2005zr}. As opposed to prior approaches, their solution models the underlying component infrastructure that implements the messaging service which allows an accurate prediction with an error within 15\% when compared to the real performance of the implemented system.

In another work, \citet{Liu:2007vn} developed a performance model of an service-oriented application based on an Enterprise Service Bus using a queuing network. Their modeling approach includes the following steps:
\begin{itemize}
	\item Mapping of application components of the design level to analytical model elements
	\item Characterisation of workload patterns for the application components used as input for performance model
	\item Calibrating the performance model
	\item Validating the performance model
\end{itemize}

\citet{DAmbrogio:2007ly} describe ``a model-driven approach for integrating performance prediction into service composition processes carried out by use of BPEL (Business Process Execution Language for Web Services).'' Using their approach, a BPEL process is described using an UML model. The model is automatically annotated with performance data and transformed into a Layered Queueing Network which is used to predict the performance of the BPEL process. For the automatic annotation of the model, a performance-oriented extension to WSDL is utilised called P-WSDL \citep{D-Ambrogio:2005ve}.

Instead of using models to compare batch and message-based processing systems, a prototype for each processing type has been built. Using prototypes in this case has the following advantages over a modelling approach:

\begin{itemize}
	\item It is difficult to build a model since every relevant aspect needs to be modelled, such as data transfer, data marshalling, database transactions.
	\item The relevant aspects for modelling the processing types were initially not known.
	\item By using state-of the art technologies and frameworks for the protoype implementation, the relevant aspects for comparing the different processing types come for ``free''.
	\item The effort to build a prototype is a compromise between creating model and a real application.
\end{itemize}

\subsection{Performance Measuring and Evaluation}
Her et al. \citep{Her:2007qf} propose the following set of metrics for measuring the performance of a service-oriented system:
\begin{itemize}
	\item \textbf{Service response time}\\
	Elapsed time between the end of request to service and the beginning of the response of the service. This metric is further split in 20 sub-metrics such as message processing time, service composition time and service discovery time.
	\item \textbf{Think time}\\
	Elapsed time between the end of a response generated by a service and the beginning of a response of an end user.
	\item \textbf{Service tournaround time}\\
	Time needed to get the result from a group of related activities within a transaction.
	\item \textbf{Throughput}\\
	Number of requests served at a given period of time. The authors distinguish between the throughput of a service and the throughput of a business process.
\end{itemize}

In their work, \citet{Henjes:2006nx,Menth:2006ys} investigated the throughput performance of the JMS server FioranaMQ, SunMQ and WebsphereMQ. The authors came to the following conclusion:
\begin{itemize}
	\item Message persistence reduces the throughput significantly.
	\item Message replication increases the overall throughput of the server.
	\item Throughput is limited either by the processing logic for small messages or by the transmission capacity for large messages.
	\item Filtering reduces the throughput significantly.
\end{itemize}

\cite{Chen:2004cr} propose that the following performance metrics should be used to evaluate a JMS server:
\begin{itemize}
	\item Maximum sustainable throughput
	\item Latency
	\item Elapsed time taken to send batches messages
	\item Persistent message loss after recovery
\end{itemize}
The authors state that ``although messaging latency is easy to understand, it is difficult to measure precisely in a distributed environment without synchronised high- precision clocks.'' They discovered that latencies increase with increasing message sizes.

SPECjms2007 is a standard benchmark for the evaluation of Message-Oriented Middleware platforms using \ac{JMS} \citep{Sachs:2009rr}. It provides a flexible performance analysis framework for tailoring the workload to specific user requirements. According to \cite{sachs2007designing}, the workload of the SPECjms2007 benchmark has to meet the following requirements:
\begin{itemize}
	\item \textbf{Representativeness}\\
	The workload should reflect how the messaging platform is used in typical user scenarios.
	\item \textbf{Comprehensiveness}\\
	The workload should incorporate all platform features typically used in JMS application including publish/subscript and point-to-point messaging.
	\item \textbf{Focus}\\
	The workload should focus on measuring the performance of the messaging middleware and should minimize the impact of other components and services.
	\item \textbf{Configurability}\\
	It should be possible to configure the workload to meet the requirements of the user.
	\item \textbf{Scalability}\\
	It should be possible to scale the workload by the number of destinations with a fixed traffic per destination or by increasing the traffic with a fixed set of destinations.
\end{itemize}

\cite{Ueno:2006ly} propose a methodology to evaluate the performance of an ESB in an early stage of development that can be used for capacity planning. Instead of using a performance model for performance prediction, they run the ESB on a real machine with a pseudo-environment using lightweight web service providers and clients. The authors state that model-based approaches ``often require elemental performance measurements and sophisticated modeling of the entire system, which is usuable not feasible for complex systems''.

Related research is concerned with the performance of messaging middleware such as \ac{JMS} servers or \ac{ESB} middleware. In the research presented in this chapter, an end-to-end performance evaluation of a batch and messaging prototype implementation has been conducted instead.

\section{Summary}\label{sec:ch4_summary}
Near-time processing of bulk data is hard to achieve. As shown in Section \ref{sec:ch2_latency_throughput}, latency and throughput are opposed performance metrics of a system for bulk data processing. Batch processing, while providding high throughput, leads to high latency, which impedes near-time processing. Message-base processing delivers low latency but cannot provide the throughput for bulk data processing due to the additional overhead for each processed message.

While it is technically possible to minimise the overhead of a messaging system by implementing a lightweight marshalling system and not use JMS or other state-of-the-art technologies such as XML, SOAP or REST, it would hurt the ability of the messaging middleware to integrate heterogenous systems or services and thus limiting its flexibility, which is one the main selling propositions of such a middleware. Furthermore, batch processing enables optimizations by partitioning and sorting the data appropriately which is not possible when each record is processed independently as a single message.

In order to compare throughput and latency of batch and message-oriented systems, a prototype for each processing type has been built. A performance evaluation has been conducted with the following results:
\begin{itemize}
	\item The throughput of the batch prototype is 4 times the throughput of the messaging prototype.
	\item The latency of the messaging prototype is only a fraction of the latency of the batch prototype.
	\item The overhead of the messaging prototype is about 84\% of the total processing time, which is mostly induced by the webservice overhead and the database transactions. 
	\item The overhead of the batch prototype is only about 7\% of the total processing time.
\end{itemize}

The results presented in Section \ref{sec:ch4_impact_granularity} show that throughput and latency depend on the granularity of data that is being processed. 
\begin{itemize}
	\item The throughput increases constantly for an aggreation size > 1 and <= 50 with a maximum of 673 events per second with an aggregation size = 50.
	\item The increased throughput achieved by increasing the aggregation size comes with the cost of a higher latency. An aggregation size of 50, resulting in the maximum throughput of 673 events per seconds, shows a 95th percentile latency of about 68 seconds. This latency is significantly higher than the latency of the messaging system without message aggregation, which is about 0,15 seconds.
	\item Increasing the aggregation size also decreases the processing overhead of the messaging prototype. An aggregate size of 10 decreases the overhead by more than 50\% compared to an aggregation size of 1.
	\item There is an optimal range for the aggregation size to control the throughput and latency of the system. Setting the aggregation size higher than a certain threshold leads to a throughput drop and latency gain cause by a congestion in the aggregator.
\end{itemize}

The performance tests that have been run for the evaluation described in section \ref{sec:ch4_evaluation} are static tests, in the sense that they do not take different load scenarios of the system into account. In a real situation, the current throughput and latency also depend on the current load of the system. If the system is not able to handle the current load, messages are congested in the input queue which increases the latency of the system. A higher maximum throughput would decrease the latency in this case. 

Therefore, the aggregation size used by the messaging system should depend on the current load of the system. It is not feasible to find a static aggregation size that works under all load conditions resulting in an optimum latency.

The next chapter presents a solution for this problem. It describes an adaptive middleware that is able to adjust the data aggregation size at runtime, depending on the current load of the system.